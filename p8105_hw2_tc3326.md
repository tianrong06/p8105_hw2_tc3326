p8105_hw2_tc3326
================
KK Chen
2024-10-02

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

## Import and clean data

Read and clean the NYC Transit data; retain line, station, name, station
latitude / longitude, routes served, entry, vending, entrance type, and
ADA compliance. Convert the entry variable from character (YES vs NO) to
a logical variable

``` r
cleaned_transit_df = 
  read_csv( "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",) |> 
  janitor::clean_names() |> 
  select("line", "station_name", "station_latitude", "station_longitude", 
    c("route1":"route11"), entry, vending, entrance_type, 
    ada) |> 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
transit_row = nrow(cleaned_transit_df)
transit_col = ncol(cleaned_transit_df)

transit_row
```

    ## [1] 1868

``` r
transit_col
```

    ## [1] 19

## Write a short paragraph about this dataset:

- This dataset contains information about NYC subway station entrances
  and exits, including variables such as the subway line, station name,
  latitude, longitude, routes (route1 to route11), entry access, vending
  machine availability, entrance type, and ADA compliance. The data was
  cleaned by selecting relevant columns, standardizing column names
  using janitor::clean_names(), and converting the entry variable from
  “YES”/“NO” to a logical TRUE/FALSE. The cleaned dataset has 1,868 rows
  and 19 columns.

## Answer the following questions using these data:

``` r
num_distinct_stations <- cleaned_transit_df |> 
  distinct(station_name, line) |> 
  nrow()

num_distinct_stations
```

    ## [1] 465

- There are 465 distinct stations.

``` r
num_ada_compliant <- cleaned_transit_df |> 
  filter(ada == TRUE) |> 
  distinct(station_name, line) |> 
  nrow()

num_ada_compliant
```

    ## [1] 84

- There are 84 stations are ADA compliant.

``` r
prop_no_vending<- cleaned_transit_df |> 
  filter(vending == "NO") |> 
  summarise(proportion = mean(entry)) |> 
  pull(proportion)

prop_no_vending
```

    ## [1] 0.3770492

- There is 0.3770492 of station entrances/exits without vending allow
  entrance.

``` r
transit_long_df <- cleaned_transit_df |> 
  mutate(across(route1:route11, as.character)) |>  
  pivot_longer(
    cols = route1:route11, 
    names_to = "route_number", 
    values_to = "route"
  ) |> 
  filter(!is.na(route))  
```

``` r
num_train_stations <- transit_long_df |> 
  filter(route == "A") |> 
  distinct(station_name, line) |> 
  nrow()

num_train_stations
```

    ## [1] 60

\*There are 60 distinct stations serve the A train

``` r
num_adacompliant_train_stations <- transit_long_df |> 
  filter(route == "A", ada == TRUE) |> 
  distinct(station_name, line) |> 
  nrow()

num_adacompliant_train_stations
```

    ## [1] 17

- There are 17 ADA compliant of the stations that serve the A train.

# Problem 2

## Read and clean the Mr. Trash Wheel data

``` r
trash_wheel_df = read_excel("./data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",
  skip = 1,
  na = c("NA", ".", "") ) |> 
  janitor::clean_names() |>  
  filter(!is.na(dumpster)) |> 
 mutate(sports_balls = as.numeric(sports_balls)) |>  
 mutate(sports_balls = round(sports_balls, 0)) |>  
 mutate(sports_balls = as.integer(sports_balls), 
    trash_wheel = "Mr. Trash Wheel" 
 )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

## Read and clean the Professor Trash Wheel data

``` r
Professor_Trash_Wheel <- read_excel(
  path = "./data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",
  na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>   
  mutate(
    which_trashwheel = "Professor Trash Wheel",
    year = as.character(year)
  )
```

## Read and clean the Gwynnda Trash Wheel data

``` r
Gwynnda_Trash_Wheel <- read_excel(
  path = "./data/202409 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",
  range = "A2:L265",  
  na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |>
  mutate(
    which_trashwheel = "Gwynnda Trash Wheel",
    year = as.character(year)
  )
```

## Combine Datasets to produce a single tidy dataset

``` r
combined_trash_wheel_df <- bind_rows(trash_wheel_df, Professor_Trash_Wheel, Gwynnda_Trash_Wheel)
```

## Calculate number of observations and total weight of trash collected by Professor Trash Wheel and total number of cigarette butts collected by Gwynnda in June of 2022.

``` r
nrow(combined_trash_wheel_df)
```

    ## [1] 1033

``` r
sum(combined_trash_wheel_df %>% filter(which_trashwheel == "Professor Trash Wheel") %>% pull(weight_tons), na.rm = TRUE)
```

    ## [1] 246.74

``` r
sum(combined_trash_wheel_df %>% filter(which_trashwheel == "Gwynnda Trash Wheel", year == "2022", month == "June") %>% pull(cigarette_butts), na.rm = TRUE)
```

    ## [1] 18120

- The combined Trash Wheel dataset contains a total of 1033 observations
  from Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel
  dataset. This dataset includes key variables such as dumpster (the
  identifier for each dumpster load), weight_tons (the weight of trash
  collected in tons), volume_cubic_yards (the volume of trash
  collected), and cigarette_butts (the number of cigarette butts
  collected). For Professor Trash Wheel, the total weight of trash
  collected across all available data is 246.74 tons. Additionally,
  Gwynnda Trash Wheel collected a total of 18120 cigarette butts in June
  of 2022. This dataset provides valuable insights about the amount and
  type of trash collected by each Trash Wheel.

# Problem 3

## read and clean bakers data

``` r
bakers_df <- read_csv(
  "./data/bakers.csv",
  na = c("NA", "N/A", "", ".")
) |>
  janitor::clean_names() |>
  mutate(baker_name = word(baker_name, 1)) |>
  rename(baker = baker_name)
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## read and clean bakes data

``` r
bakes_df <- read_csv(
  "./data/bakes.csv",
  na = c("NA", "N/A", "", ".")
) |>
  janitor::clean_names() |>
 mutate(
    baker = if_else(baker == '"Jo"', "Jo", baker)
    ) 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## read and clean results data

``` r
results_df <- read_csv(
  "./data/results.csv",
  skip = 2,
  na = c("NA", "N/A", "", ".")
) |>
 janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Check for bakers in `bakes_df` that are not present in `bakers_df`

``` r
missing_in_bakers <- anti_join(bakes_df, bakers_df, by = c("baker","series") )
print(missing_in_bakers)
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

## Check for bakers in `results_df` that are not present in `bakers_df`

``` r
missing_in_results <- anti_join(results_df, bakers_df, by = c("baker","series") )
print(missing_in_results)
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

## Merge `bakes_df` with `bakers_df` using `baker` and `series`

``` r
combined_df <- results_df |> left_join(bakers_df, by = c("baker", "series"))
```

## Merge the resulting dataset with `results_df` using `baker`, `series`, and `episode`

``` r
final_df <- combined_df |> left_join(bakes_df, by = c("baker", "series", "episode"))
```

## Export the result as a CSV

``` r
write_csv(final_df, "./final_baking_dataset.csv")
```

## Describe your data cleaning process. Briefly discuss the final dataset.

- The data cleaning process involved importing and standardizing column
  names in the `bakers.csv`, `bakes.csv`, and `results.csv` datasets
  using `clean_names()`. In `bakers.csv`, we extracted only the first
  name from `baker_name` to facilitate merging. In `bakes.csv`, we
  corrected inconsistencies, such as removing quotation marks around
  “Jo”, to ensure consistency in the baker column. We used `anti_join()`
  to identify mismatches between the datasets and resolved discrepancies
  before merging. The datasets were then merged using `baker`, `series`,
  and `episode` as keys to create a unified dataset, which was exported
  as `final_baking_dataset.csv`.

- The final dataset `final_baking_dataset.csv` is a comprehensive
  collection of information on bakers, their bakes, and their
  performance across different series and episodes of the show. The key
  columns include `series`, `episode`, `baker`, `baker_age`,
  `baker_occupation`, `hometown`, `signature_bake`, `show_stoppe`,
  `technical`, and `result`. By merging data from `bakers.csv`,
  `bakes.csv`, and `results.csv`, the dataset captures each baker’s
  journey and progression throughout the series. To enhance readability,
  columns were reorganized, and the data was sorted by `series`,
  `episode`, and `baker`. This structure allows for a detailed analysis
  of baking performance, trends, and outcomes within the competition.

## Create a reader-friendly table

``` r
summary_table <- final_df %>%
  filter(series >= 5 & series <= 10) %>%
  filter(result == "STAR BAKER" | result == "WINNER") %>%
  arrange(series, episode, baker) %>%
  select(series, episode, baker, technical,result, baker_age)
```

- Winners generally ranked high in technicals. Star Bakers’ technical
  appear to be less significant.
- Most winners in the table had previously been named Star Bakers at
  least once. However, an exception is David who is the winner at the
  end without ever being named Star Baker before.

## Import, clean, tidy, and organize the viewership data in viewers.csv.

``` r
viewers_df = read_csv("./data/viewers.csv") %>% 
  janitor::clean_names()%>%
  head(10)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## the average viewership in Season 1 and In Season 5

``` r
average_viewership_1 = viewers_df %>% 
  pull(series_1)
mean(average_viewership_1, na.rm = TRUE)
```

    ## [1] 2.77

``` r
average_viewership_5 = viewers_df %>% 
  pull(series_5)
mean(average_viewership_5, na.rm = TRUE)
```

    ## [1] 10.0393

- The average viewership in Season 1 was 2.77, in Season 5 was 10.0393.
